{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVabmztYXVS6"
      },
      "outputs": [],
      "source": [
        "# EHR Patient Outcome Prediction (Text (clinical notes) + Tabular features)\n",
        "# TensorFlow 2.x full runnable example (synthetic data)\n",
        "# Run in Google Colab or local environment with TF installed.\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 1) Synthetic dataset\n",
        "# -------------------------\n",
        "def synth_clinical_note(label):\n",
        "    # simple synthetic clinical note generator with keywords correlated to label\n",
        "    base_notes = [\n",
        "        \"patient complains of chest pain and shortness of breath\",\n",
        "        \"fever, cough, and sore throat for three days\",\n",
        "        \"elevated blood pressure, headache, dizziness\",\n",
        "        \"postoperative follow up, incision clean, no drainage\",\n",
        "        \"diabetic patient with high blood sugar and neuropathy\",\n",
        "        \"severe infection, septic, required IV antibiotics\",\n",
        "        \"mild abdominal pain, tolerating oral intake\",\n",
        "        \"fall with hip pain, imaging recommended\",\n",
        "        \"chest x-ray shows infiltrates consistent with pneumonia\",\n",
        "        \"stable vitals, ambulating, discharge planned\"\n",
        "    ]\n",
        "    # bias words for positive outcome (readmission = 1)\n",
        "    if label == 1:\n",
        "        additions = [\n",
        "            \"recurrent\", \"worsening\", \"unstable\", \"requires readmission\",\n",
        "            \"acute deterioration\", \"sepsis\", \"respiratory failure\"\n",
        "        ]\n",
        "    else:\n",
        "        additions = [\n",
        "            \"stable\", \"improved\", \"discharged\", \"outpatient follow up\",\n",
        "            \"no complications\", \"stable for discharge\"\n",
        "        ]\n",
        "    note = random.choice(base_notes)\n",
        "    note += \". \" + \" \".join(random.choices(additions, k=2))\n",
        "    # add a few random tokens for variability\n",
        "    extras = [\"history of hypertension\", \"allergic to penicillin\", \"smoker\",\n",
        "              \"no known drug allergies\", \"family history of diabetes\", \"on metformin\"]\n",
        "    note += \". \" + random.choice(extras)\n",
        "    return note\n",
        "\n",
        "N = 8000  # dataset size\n",
        "# Create structured features: age, gender, num_prior_admissions, length_of_stay, lab_score (synthetic)\n",
        "rows = []\n",
        "for i in range(N):\n",
        "    # synthetic risk score to drive label generation\n",
        "    age = np.random.randint(18, 95)\n",
        "    gender = np.random.choice([0, 1])  # 0 female, 1 male\n",
        "    num_prior = np.random.poisson(0.8)\n",
        "    los = max(1, int(np.random.exponential(3)))  # length of stay\n",
        "    lab_score = np.clip(np.random.normal(0.0 + 0.03*(age-60) + 0.7*(num_prior), 1.0), -3, 3)\n",
        "    # Compute probability of readmission (synthetic logistic)\n",
        "    logit = -3.0 + 0.02*(age) + 0.7*(num_prior) + 0.6*(los>5) + 0.9*lab_score + 0.2*gender\n",
        "    prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "    label = np.random.binomial(1, prob)\n",
        "    note = synth_clinical_note(label)\n",
        "    rows.append({\n",
        "        \"note\": note,\n",
        "        \"age\": age,\n",
        "        \"gender\": gender,\n",
        "        \"num_prior\": num_prior,\n",
        "        \"los\": los,\n",
        "        \"lab_score\": lab_score,\n",
        "        \"readmit\": label\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhJOgFVUYJIo",
        "outputId": "84acaf27-f876-4629-f201-6a3a67c9313f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (8000, 7)\n",
            "                                                note  age  gender  num_prior  \\\n",
            "0  fever, cough, and sore throat for three days. ...   69       0          0   \n",
            "1  elevated blood pressure, headache, dizziness. ...   92       1          0   \n",
            "2  fever, cough, and sore throat for three days. ...   70       1          2   \n",
            "3  postoperative follow up, incision clean, no dr...   66       0          1   \n",
            "4  postoperative follow up, incision clean, no dr...   79       1          1   \n",
            "\n",
            "   los  lab_score  readmit  \n",
            "0    4  -0.927806        0  \n",
            "1    1   3.000000        1  \n",
            "2   14   3.000000        1  \n",
            "3    1   2.418715        1  \n",
            "4    2   0.725617        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 2) Train/Val/Test split\n",
        "# -------------------------\n",
        "train_df, test_df = train_test_split(df, test_size=0.15, random_state=SEED, stratify=df[\"readmit\"])\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=SEED, stratify=train_df[\"readmit\"])\n",
        "\n",
        "X_train_text = train_df[\"note\"].astype(str).to_numpy()\n",
        "X_val_text   = val_df[\"note\"].astype(str).to_numpy()\n",
        "X_test_text  = test_df[\"note\"].astype(str).to_numpy()\n",
        "\n",
        "tabular_cols = [\"age\", \"gender\", \"num_prior\", \"los\", \"lab_score\"]\n",
        "X_train_tab = train_df[tabular_cols].to_numpy()\n",
        "X_val_tab   = val_df[tabular_cols].to_numpy()\n",
        "X_test_tab  = test_df[tabular_cols].to_numpy()\n",
        "\n",
        "y_train = train_df[\"readmit\"].to_numpy()\n",
        "y_val   = val_df[\"readmit\"].to_numpy()\n",
        "y_test  = test_df[\"readmit\"].to_numpy()\n",
        "\n",
        "# Standardize tabular data\n",
        "scaler = StandardScaler()\n",
        "X_train_tab = scaler.fit_transform(X_train_tab)\n",
        "X_val_tab = scaler.transform(X_val_tab)\n",
        "X_test_tab = scaler.transform(X_test_tab)"
      ],
      "metadata": {
        "id": "YilWyT0EYQkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 3) Text preprocessing: TextVectorization\n",
        "# -------------------------\n",
        "max_tokens = 20000\n",
        "max_len = 120\n",
        "\n",
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_len\n",
        ")\n",
        "# adapt on training text\n",
        "text_vectorizer.adapt(X_train_text)"
      ],
      "metadata": {
        "id": "O3Kh9c4yYZSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4) Build TF Dataset pipelines\n",
        "# -------------------------\n",
        "batch_size = 64\n",
        "\n",
        "def make_dataset(texts, tabs, labels, shuffle=False, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((texts, tabs), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(labels), seed=SEED)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(X_train_text, X_train_tab, y_train, shuffle=True, batch_size=batch_size)\n",
        "val_ds = make_dataset(X_val_text, X_val_tab, y_val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = make_dataset(X_test_text, X_test_tab, y_test, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "1SQ64vJ5Yd9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EHR Patient Outcome Prediction (Text (clinical notes) + Tabular features)\n",
        "# TensorFlow 2.x full runnable example (synthetic data)\n",
        "# Run in Google Colab or local environment with TF installed.\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Synthetic dataset\n",
        "# -------------------------\n",
        "def synth_clinical_note(label):\n",
        "    # simple synthetic clinical note generator with keywords correlated to label\n",
        "    base_notes = [\n",
        "        \"patient complains of chest pain and shortness of breath\",\n",
        "        \"fever, cough, and sore throat for three days\",\n",
        "        \"elevated blood pressure, headache, dizziness\",\n",
        "        \"postoperative follow up, incision clean, no drainage\",\n",
        "        \"diabetic patient with high blood sugar and neuropathy\",\n",
        "        \"severe infection, septic, required IV antibiotics\",\n",
        "        \"mild abdominal pain, tolerating oral intake\",\n",
        "        \"fall with hip pain, imaging recommended\",\n",
        "        \"chest x-ray shows infiltrates consistent with pneumonia\",\n",
        "        \"stable vitals, ambulating, discharge planned\"\n",
        "    ]\n",
        "    # bias words for positive outcome (readmission = 1)\n",
        "    if label == 1:\n",
        "        additions = [\n",
        "            \"recurrent\", \"worsening\", \"unstable\", \"requires readmission\",\n",
        "            \"acute deterioration\", \"sepsis\", \"respiratory failure\"\n",
        "        ]\n",
        "    else:\n",
        "        additions = [\n",
        "            \"stable\", \"improved\", \"discharged\", \"outpatient follow up\",\n",
        "            \"no complications\", \"stable for discharge\"\n",
        "        ]\n",
        "    note = random.choice(base_notes)\n",
        "    note += \". \" + \" \".join(random.choices(additions, k=2))\n",
        "    # add a few random tokens for variability\n",
        "    extras = [\"history of hypertension\", \"allergic to penicillin\", \"smoker\",\n",
        "              \"no known drug allergies\", \"family history of diabetes\", \"on metformin\"]\n",
        "    note += \". \" + random.choice(extras)\n",
        "    return note\n",
        "\n",
        "N = 8000  # dataset size\n",
        "# Create structured features: age, gender, num_prior_admissions, length_of_stay, lab_score (synthetic)\n",
        "rows = []\n",
        "for i in range(N):\n",
        "    # synthetic risk score to drive label generation\n",
        "    age = np.random.randint(18, 95)\n",
        "    gender = np.random.choice([0, 1])  # 0 female, 1 male\n",
        "    num_prior = np.random.poisson(0.8)\n",
        "    los = max(1, int(np.random.exponential(3)))  # length of stay\n",
        "    lab_score = np.clip(np.random.normal(0.0 + 0.03*(age-60) + 0.7*(num_prior), 1.0), -3, 3)\n",
        "    # Compute probability of readmission (synthetic logistic)\n",
        "    logit = -3.0 + 0.02*(age) + 0.7*(num_prior) + 0.6*(los>5) + 0.9*lab_score + 0.2*gender\n",
        "    prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "    label = np.random.binomial(1, prob)\n",
        "    note = synth_clinical_note(label)\n",
        "    rows.append({\n",
        "        \"note\": note,\n",
        "        \"age\": age,\n",
        "        \"gender\": gender,\n",
        "        \"num_prior\": num_prior,\n",
        "        \"los\": los,\n",
        "        \"lab_score\": lab_score,\n",
        "        \"readmit\": label\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# -------------------------\n",
        "# 2) Train/Val/Test split\n",
        "# -------------------------\n",
        "train_df, test_df = train_test_split(df, test_size=0.15, random_state=SEED, stratify=df[\"readmit\"])\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=SEED, stratify=train_df[\"readmit\"])\n",
        "\n",
        "X_train_text = train_df[\"note\"].astype(str).to_numpy()\n",
        "X_val_text   = val_df[\"note\"].astype(str).to_numpy()\n",
        "X_test_text  = test_df[\"note\"].astype(str).to_numpy()\n",
        "\n",
        "tabular_cols = [\"age\", \"gender\", \"num_prior\", \"los\", \"lab_score\"]\n",
        "X_train_tab = train_df[tabular_cols].to_numpy()\n",
        "X_val_tab   = val_df[tabular_cols].to_numpy()\n",
        "X_test_tab  = test_df[tabular_cols].to_numpy()\n",
        "\n",
        "y_train = train_df[\"readmit\"].to_numpy()\n",
        "y_val   = val_df[\"readmit\"].to_numpy()\n",
        "y_test  = test_df[\"readmit\"].to_numpy()\n",
        "\n",
        "# Standardize tabular data\n",
        "scaler = StandardScaler()\n",
        "X_train_tab = scaler.fit_transform(X_train_tab)\n",
        "X_val_tab = scaler.transform(X_val_tab)\n",
        "X_test_tab = scaler.transform(X_test_tab)\n",
        "\n",
        "# -------------------------\n",
        "# 3) Text preprocessing: TextVectorization\n",
        "# -------------------------\n",
        "max_tokens = 20000\n",
        "max_len = 120\n",
        "\n",
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_len\n",
        ")\n",
        "# adapt on training text\n",
        "text_vectorizer.adapt(X_train_text)\n",
        "\n",
        "# -------------------------\n",
        "# 4) Build TF Dataset pipelines\n",
        "# -------------------------\n",
        "batch_size = 64\n",
        "\n",
        "def make_dataset(texts, tabs, labels, shuffle=False, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(((texts, tabs), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(labels), seed=SEED)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(X_train_text, X_train_tab, y_train, shuffle=True, batch_size=batch_size)\n",
        "val_ds = make_dataset(X_val_text, X_val_tab, y_val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = make_dataset(X_test_text, X_test_tab, y_test, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "# -------------------------\n",
        "# 5) Model: Text branch (Embedding + BiLSTM), Tabular branch (Dense), combine\n",
        "# -------------------------\n",
        "# Text input\n",
        "text_input = keras.Input(shape=(), dtype=\"string\", name=\"note\")\n",
        "x = text_vectorizer(text_input)                          # ints\n",
        "vocab_size = int(text_vectorizer.vocabulary_size())\n",
        "embed_dim = 128\n",
        "x = layers.Embedding(input_dim=vocab_size + 1, output_dim=embed_dim, mask_zero=True)(x)\n",
        "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Tabular input\n",
        "tab_input = keras.Input(shape=(len(tabular_cols),), dtype=\"float32\", name=\"tabular\")\n",
        "t = layers.Dense(64, activation=\"relu\")(tab_input)\n",
        "t = layers.BatchNormalization()(t)\n",
        "t = layers.Dropout(0.2)(t)\n",
        "t = layers.Dense(32, activation=\"relu\")(t)\n",
        "\n",
        "# Combine\n",
        "combined = layers.concatenate([x, t])\n",
        "combined = layers.Dense(64, activation=\"relu\")(combined)\n",
        "combined = layers.Dropout(0.4)(combined)\n",
        "combined = layers.Dense(32, activation=\"relu\")(combined)\n",
        "output = layers.Dense(1, activation=\"sigmoid\", name=\"readmit\")(combined)\n",
        "\n",
        "model = keras.Model(inputs=[text_input, tab_input], outputs=output, name=\"ehr_text_tab_model\")\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "             keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s6DImwAHYjpN",
        "outputId": "d87dcad7-cb3e-4b71-d8f9-9cd41ad7dd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (8000, 7)\n",
            "                                                note  age  gender  num_prior  \\\n",
            "0  fever, cough, and sore throat for three days. ...   69       0          0   \n",
            "1  elevated blood pressure, headache, dizziness. ...   92       1          0   \n",
            "2  fever, cough, and sore throat for three days. ...   70       1          2   \n",
            "3  postoperative follow up, incision clean, no dr...   66       0          1   \n",
            "4  postoperative follow up, incision clean, no dr...   79       1          1   \n",
            "\n",
            "   los  lab_score  readmit  \n",
            "0    4  -0.927806        0  \n",
            "1    1   3.000000        1  \n",
            "2   14   3.000000        1  \n",
            "3    1   2.418715        1  \n",
            "4    2   0.725617        0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'global_max_pooling1d' (of type GlobalMaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ehr_text_tab_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ehr_text_tab_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ note (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ text_vectorization… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ note[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m11,136\u001b[0m │ text_vectorizati… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ text_vectorizati… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ tabular             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m263,168\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m384\u001b[0m │ tabular[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m6,208\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ readmit (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ note (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ text_vectorization… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ note[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,136</span> │ text_vectorizati… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_vectorizati… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ tabular             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ tabular[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ readmit (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301,793\u001b[0m (1.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,793</span> (1.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301,665\u001b[0m (1.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,665</span> (1.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YUK9u2WZBej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 7) Callbacks\n",
        "# -------------------------\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\"ehr_text_tab_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
        "]\n"
      ],
      "metadata": {
        "id": "2NgYMS5AZSfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "34e4a464-97c5-4286-feae-8f08855ed3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'keras' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3730821679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m callbacks = [\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ehr_text_tab_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 8) Train\n",
        "# -------------------------\n",
        "# -------------------------\n",
        "# 6) Calculate class weights for imbalanced data\n",
        "# -------------------------\n",
        "# Calculate class counts\n",
        "class_counts = train_df['readmit'].value_counts()\n",
        "\n",
        "# Calculate total number of samples\n",
        "total_samples = class_counts.sum()\n",
        "\n",
        "# Calculate weights for each class\n",
        "# weight = total_samples / (num_classes * count_of_class)\n",
        "num_classes = len(class_counts)\n",
        "class_weight = {i: total_samples / (num_classes * count) for i, count in class_counts.items()}\n",
        "\n",
        "print(\"Class weights:\", class_weight)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0dLtrRtrZWZK",
        "outputId": "d0bb6afb-1832-4cc8-8e17-0892e25958a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-589711156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate class counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'readmit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculate total number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186b4fe5",
        "outputId": "e04535b9-4946-4d6c-fdc3-359602104e37"
      },
      "source": [
        "# -------------------------\n",
        "# 6) Calculate class weights for imbalanced data\n",
        "# -------------------------\n",
        "# Calculate class counts\n",
        "class_counts = train_df['readmit'].value_counts()\n",
        "\n",
        "# Calculate total number of samples\n",
        "total_samples = class_counts.sum()\n",
        "\n",
        "# Calculate weights for each class\n",
        "# weight = total_samples / (num_classes * count_of_class)\n",
        "num_classes = len(class_counts)\n",
        "class_weight = {i: total_samples / (num_classes * count) for i, count in class_counts.items()}\n",
        "\n",
        "print(\"Class weights:\", class_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(0.8065866592241139), 1: np.float64(1.3154301319981794)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 9) Evaluate on test set\n",
        "# -------------------------\n",
        "results = model.evaluate(test_ds, verbose=1)\n",
        "print(\"Test loss, Test acc, Test AUC:\", results)\n",
        "\n",
        "# Predict and show classification report\n",
        "y_pred_prob = model.predict(test_ds)\n",
        "y_pred = (y_pred_prob.ravel() >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report (Test):\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaOGAsCYZeqz",
        "outputId": "ff63e779-1345-4aac-e2c1-49ae5f3dee4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'global_max_pooling1d_2' (of type GlobalMaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 268ms/step - accuracy: 0.3840 - auc: 0.4612 - loss: 0.6959\n",
            "Test loss, Test acc, Test AUC: [0.6961308717727661, 0.3916666805744171, 0.45164090394973755]\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step\n",
            "\n",
            "Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5201    0.2433    0.3315       744\n",
            "           1     0.3392    0.6338    0.4419       456\n",
            "\n",
            "    accuracy                         0.3917      1200\n",
            "   macro avg     0.4297    0.4385    0.3867      1200\n",
            "weighted avg     0.4514    0.3917    0.3735      1200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[181 563]\n",
            " [167 289]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 10) Example inference function\n",
        "# -------------------------\n",
        "def predict_single(note_text, tab_features_array):\n",
        "    \"\"\"\n",
        "    note_text: string (will be vectorized inside function)\n",
        "    tab_features_array: array-like of shape (len(tabular_cols),) in original scale (before StandardScaler)\n",
        "    \"\"\"\n",
        "    tab_arr = np.array(tab_features_array).reshape(1, -1)\n",
        "    tab_arr_scaled = scaler.transform(tab_arr)\n",
        "\n",
        "    # Convert single string to numpy array of strings before vectorization\n",
        "    text_np_array = np.array([note_text], dtype=object) # Use dtype=object for variable-length strings\n",
        "\n",
        "    # Vectorize the text input before passing to the model\n",
        "    text_vectorized = text_vectorizer(text_np_array) # Vectorize numpy array input\n",
        "\n",
        "    print(f\"Vectorized text dtype: {text_vectorized.dtype}\")\n",
        "    print(f\"Vectorized text shape: {text_vectorized.shape}\")\n",
        "    print(f\"Tabular tensor dtype: {tab_arr_scaled.dtype}\")\n",
        "    print(f\"Tabular tensor shape: {tab_arr_scaled.shape}\")\n",
        "\n",
        "\n",
        "    # Pass inputs as a dictionary\n",
        "    prob = model.predict({\"note\": text_vectorized, \"tabular\": tab_arr_scaled})\n",
        "    prob_val = float(prob[0][0])\n",
        "    percent = round(prob_val * 100, 2)\n",
        "\n",
        "    if prob_val >= 0.5:\n",
        "        print(f\"Prediction: HIGH RISK of readmission ({percent}% probability).\")\n",
        "        print(f\"➡ Out of 100 similar patients, about {percent} may be readmitted.\")\n",
        "    else:\n",
        "        print(f\"Prediction: LOW RISK of readmission ({percent}% probability).\")\n",
        "        print(f\"➡ Out of 100 similar patients, about {percent} may be readmitted.\")\n",
        "\n",
        "    return prob_val\n",
        "\n",
        "# Example\n",
        "example_note = \"Patient with fever and cough, worsening shortness of breath. Recurrent admissions for pneumonia.\"\n",
        "example_tab = [72, 1, 2, 6, 1.5]  # age, gender, num_prior, los, lab_score\n",
        "print(\"\\nExample prediction (prob of readmit):\", predict_single(example_note, example_tab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFqh2TAQkC-4",
        "outputId": "341f36a9-fd05-4479-8bd8-523ba77c42a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized text dtype: <dtype: 'int64'>\n",
            "Vectorized text shape: (1, 120)\n",
            "Tabular tensor dtype: float64\n",
            "Tabular tensor shape: (1, 5)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Prediction: LOW RISK of readmission (48.6% probability).\n",
            "➡ Out of 100 similar patients, about 48.6 may be readmitted.\n",
            "\n",
            "Example prediction (prob of readmit): 0.4860389232635498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 11) Save preprocessing objects (vectorizer & scaler) and model\n",
        "# -------------------------\n",
        "# Save Keras model architecture to JSON and weights to HDF5\n",
        "model_json = model.to_json()\n",
        "with open(\"ehr_text_tab_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# Save weights\n",
        "model.save_weights(\"ehr_text_tab_model_weights.weights.h5\")\n",
        "\n",
        "\n",
        "# Save text_vectorizer vocabulary\n",
        "vocab = text_vectorizer.get_vocabulary()\n",
        "with open(\"text_vectorizer_vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(vocab))\n",
        "\n",
        "# Save scaler params\n",
        "np.savez(\"tabular_scaler_params.npz\", mean=scaler.mean_, scale=scaler.scale_)\n",
        "\n",
        "print(\"\\nSaved model architecture to 'ehr_text_tab_model.json', weights to 'ehr_text_tab_model_weights.weights.h5', vocab to 'text_vectorizer_vocab.txt', scaler to 'tabular_scaler_params.npz'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tuKbaMAkSkc",
        "outputId": "393622d9-c8dc-4d58-ab89-b1b135067c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved model architecture to 'ehr_text_tab_model.json', weights to 'ehr_text_tab_model_weights.weights.h5', vocab to 'text_vectorizer_vocab.txt', scaler to 'tabular_scaler_params.npz'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "310625bd",
        "outputId": "450baccd-2205-4ae9-af8d-32ccbe424cae"
      },
      "source": [
        "# -------------------------\n",
        "# 5) Model: Text branch (Embedding + BiLSTM), Tabular branch (Dense), combine\n",
        "# -------------------------\n",
        "# Text input - now accepts integer sequences\n",
        "text_input = keras.Input(shape=(max_len,), dtype=\"int64\", name=\"note\") # Changed dtype to int64 and shape to (max_len,)\n",
        "x = layers.Embedding(input_dim=vocab_size + 1, output_dim=embed_dim, mask_zero=True)(text_input) # Use text_input directly\n",
        "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Tabular input\n",
        "tab_input = keras.Input(shape=(len(tabular_cols),), dtype=\"float32\", name=\"tabular\")\n",
        "t = layers.Dense(64, activation=\"relu\")(tab_input)\n",
        "t = layers.BatchNormalization()(t)\n",
        "t = layers.Dropout(0.2)(t)\n",
        "t = layers.Dense(32, activation=\"relu\")(t)\n",
        "\n",
        "# Combine\n",
        "combined = layers.concatenate([x, t])\n",
        "combined = layers.Dense(64, activation=\"relu\")(combined)\n",
        "combined = layers.Dropout(0.4)(combined)\n",
        "combined = layers.Dense(32, activation=\"relu\")(combined)\n",
        "output = layers.Dense(1, activation=\"sigmoid\", name=\"readmit\")(combined)\n",
        "\n",
        "model = keras.Model(inputs=[text_input, tab_input], outputs=output, name=\"ehr_text_tab_model\")\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "             keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'global_max_pooling1d_5' (of type GlobalMaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ehr_text_tab_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ehr_text_tab_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ note (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m11,136\u001b[0m │ note[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ note[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ tabular             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m263,168\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m384\u001b[0m │ tabular[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m6,208\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ readmit (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ note (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,136</span> │ note[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ note[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ tabular             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ tabular[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ readmit (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301,793\u001b[0m (1.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,793</span> (1.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301,665\u001b[0m (1.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,665</span> (1.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 10) Example inference function\n",
        "# -------------------------\n",
        "def predict_single(note_text, tab_features_array):\n",
        "    \"\"\"\n",
        "    note_text: string (will be vectorized inside function)\n",
        "    tab_features_array: array-like of shape (len(tabular_cols),) in original scale (before StandardScaler)\n",
        "    \"\"\"\n",
        "    tab_arr = np.array(tab_features_array).reshape(1, -1)\n",
        "    tab_arr_scaled = scaler.transform(tab_arr)\n",
        "\n",
        "    # Convert single string to numpy array of strings before vectorization\n",
        "    text_np_array = np.array([note_text], dtype=object) # Use dtype=object for variable-length strings\n",
        "\n",
        "    # Vectorize the text input before passing to the model\n",
        "    text_vectorized = text_vectorizer(text_np_array) # Vectorize numpy array input\n",
        "\n",
        "    print(f\"Vectorized text dtype: {text_vectorized.dtype}\")\n",
        "    print(f\"Vectorized text shape: {text_vectorized.shape}\")\n",
        "    print(f\"Tabular tensor dtype: {tab_arr_scaled.dtype}\")\n",
        "    print(f\"Tabular tensor shape: {tab_arr_scaled.shape}\")\n",
        "\n",
        "\n",
        "    # Pass inputs as a dictionary\n",
        "    prob = model.predict({\"note\": text_vectorized, \"tabular\": tab_arr_scaled})\n",
        "    prob_val = float(prob[0][0])\n",
        "    percent = round(prob_val * 100, 2)\n",
        "\n",
        "    if prob_val >= 0.5:\n",
        "        print(f\"Prediction: HIGH RISK of readmission ({percent}% probability).\")\n",
        "        print(f\"➡ Out of 100 similar patients, about {percent} may be readmitted.\")\n",
        "    else:\n",
        "        print(f\"Prediction: LOW RISK of readmission ({percent}% probability).\")\n",
        "        print(f\"➡ Out of 100 similar patients, about {percent} may be readmitted.\")\n",
        "\n",
        "    return prob_val\n",
        "\n",
        "# Example\n",
        "example_note = \"Patient with fever and cough, worsening shortness of breath. Recurrent admissions for pneumonia.\"\n",
        "example_tab = [72, 1, 2, 6, 1.5]  # age, gender, num_prior, los, lab_score\n",
        "print(\"\\nExample prediction (prob of readmit):\", predict_single(example_note, example_tab))"
      ],
      "metadata": {
        "id": "AUo5plV2mcSu",
        "outputId": "b0f53ed1-682c-4686-d78d-60495281905e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized text dtype: <dtype: 'int64'>\n",
            "Vectorized text shape: (1, 120)\n",
            "Tabular tensor dtype: float64\n",
            "Tabular tensor shape: (1, 5)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Prediction: LOW RISK of readmission (48.6% probability).\n",
            "➡ Out of 100 similar patients, about 48.6 may be readmitted.\n",
            "\n",
            "Example prediction (prob of readmit): 0.4860389232635498\n"
          ]
        }
      ]
    }
  ]
}